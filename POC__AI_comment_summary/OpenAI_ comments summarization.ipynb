{"cells":[{"cell_type":"markdown","source":["### ENV: Microsoft Fabric\n","### Model: OpenAI"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"77e97a03-a6ef-48e0-850e-86e0b5affd28"},{"cell_type":"code","source":["import pandas as pd\n","import openai"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"605d7f96-5b50-4d42-80ff-7da597f2ef49"},{"cell_type":"code","source":["# OPTION NOT USED IN THIS CASE:\n","\n","# use python-dotenv, generate a .env file to handle access credentials separately (see documentation)\n","# in Azure, you can pay for Azure OpenAI\n","'''\n","from dotenv import load_dotenv\n","import os\n","\n","load_dotenv()\n","openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n","'''"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ad440b3c-6c19-43a7-83be-cff216638b45"},{"cell_type":"code","source":["# since we're not using .env, we load the key directly here\n","\n","# 1. Set up your API key (see below for how to obtain it)\n","openai.api_key = \"TU_API_KEY_AQU√ç\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"74300a58-2c7a-4f25-91fd-df53f92d9afb"},{"cell_type":"code","source":["# 2. dataset\n","df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"abfss://Testing@onelake.dfs.fabric.microsoft.com/TestLake.Lakehouse/Files/nps_result.csv\")\n","# df now is a Spark DataFrame containing CSV data from \"abfss://Testing@onelake.dfs.fabric.microsoft.com/TestLake.Lakehouse/Files/nps_result.csv\".\n"],"outputs":[],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"58fc7fbf-d2e1-4d23-b06b-f9706fb6aa75"},{"cell_type":"code","source":["\n","\n","# 3. Group comments by score\n","agrupado = df.groupby(\"score\")[\"comment\"].apply(lambda x: \" \".join(str(c) for c in x)).reset_index()\n","\n","# 4. Function to generate summary using OpenAI\n","def summarize_comments(texto, puntaje):\n","    prompt = f\"\"\"\n","            I have a list of customer comments who gave a score of {score}.\n","            Some comments are irrelevant or empty (such as \"na\", \"??\", \".\", \"...\", etc.).\n","            Ignore those cases and generate a clear summary of the actual opinions.\n","\n","            Commments:\n","            {text}\n","\n","            Summary:\n","            \"\"\"\n","    try:\n","        answer = openai.ChatCompletion.create(\n","            #  usa \"gpt-3.5-turbo\", if cannot use GPT-4\n","            model=\"gpt-4\",\n","            # rol type (user, assistant, system)\n","            messages=[{\"role\": \"user\", \"content\": prompt.strip()}], \n","            # creativity: 0 means very conservative, 1 means very creative.\n","            temperature=0.4,\n","            # How many words (tokens) can it return to you at most\n","            max_tokens=200\n","            )\n","        return answer.choices[0].message[\"content\"].strip()\n","    except Exception as e:\n","        return f\"Error: {e}\"\n","\n","# 5. Apply the summary for each score group\n","agrupado[\"resumen\"] = agrupado.apply(lambda row: summarize_comments(row[\"comment\"], row[\"score\"]), axis=1)\n","\n","# 6. result\n","print(agrupado[[\"score\", \"resumen\"]])\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b1848320-bfaa-45d3-a04e-72eaeef2e78b"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"76ed5a75-933e-49e9-95ed-bd243fce2395"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"b1c60b7e-15e4-438b-a99c-584b8d00e273"}],"default_lakehouse":"b1c60b7e-15e4-438b-a99c-584b8d00e273","default_lakehouse_name":"TestLake","default_lakehouse_workspace_id":"d8315185-d82a-4127-bc3a-a00cb9ea4bc6"}}},"nbformat":4,"nbformat_minor":5}