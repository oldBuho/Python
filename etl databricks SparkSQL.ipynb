{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "af34bcfe-ef1d-4af6-bb4b-57c9affcb094",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# modules\n",
    "import os, sys\n",
    "import traceback\n",
    "import itertools\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark\n",
    "from time import time\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from pyspark.sql.functions import col, unix_timestamp, format_number\n",
    "#import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "from datetime import datetime, timedelta\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from pyspark import SparkFiles\n",
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7605c2d-7d88-460e-b483-49c573ff8817",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conf = {}\n",
    "\n",
    "conf['jdbcDriver_origin'] = dbutils.secrets.get('key-vault-company-secrets','sql-company-system-jdbcdriver')\n",
    "conf['jdbcUsername_origin'] = dbutils.secrets.get('key-vault-company-secrets','sql-company-system-username')\n",
    "conf['jdbcPassword_origin'] = dbutils.secrets.get('key-vault-company-secrets','sql-company-system-password')\n",
    "conf['jdbcUrl_origin'] = dbutils.secrets.get('key-vault-company-secrets','sql-company-system-jdbcurl')\n",
    "\n",
    "conf['jdbcDriver_destination'] = dbutils.secrets.get('key-vault-company-secrets','sql-companyDummy-dw-jdbcdriver')\n",
    "conf['jdbcUrl_destination'] = dbutils.secrets.get('key-vault-company-secrets','sql-companyDummy-dw-jdbcurl')\n",
    "conf['jdbcUsername_destination'] = dbutils.secrets.get('key-vault-company-secrets','sql-companyDummy-dw-username')\n",
    "conf['jdbcPassword_destination'] = dbutils.secrets.get('key-vault-company-secrets','sql-companyDummy-dw-password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc686a91-6376-4de4-af83-8f4db645e7a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully\n"
     ]
    }
   ],
   "source": [
    "# SQL Azure connection\n",
    "\n",
    "max_attempts = 15\n",
    "seconds_to_wait = 5\n",
    "\n",
    "for attempt in range(max_attempts):\n",
    "\n",
    "    try:\n",
    "        dfSQLTestCon = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.Dim_Country\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).load()\n",
    "        \n",
    "        print(\"Connected successfully\")\n",
    "        break\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error to connect: {}\".format(attempt))\n",
    "        print(e)\n",
    "        print(\"Waiting {} seconds ...\".format(seconds_to_wait))\n",
    "        time.sleep(seconds_to_wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a475890c-a8ba-4535-9e5f-20a2e3cb37d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Brand: VW_BI_CAT_BRAND\n",
    "\n",
    "df_dim_brand = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_CAT_BRAND\").load()\n",
    "\n",
    "df_dim_brand.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Brand]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74bdec88-4f1c-4eb1-99fd-f9a279001555",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Product: join views VW_CAT_PRODUCT, W_CAT_PRODUCT_TYPE, VW_BI_CAT_TIER, VW_CAT_SEGMENT, VW_BI_CAT_PRODUCT_CATEGORY, VW_BI_SUPER_CATEGORY, VW_CAT_SUB_BRAND\n",
    "\n",
    "df_dim_product = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"SELECT p.id, p.name, p.active, p.sku, p.ean, p.product_type, pt.name as product_type_name, pt.active as product_type_active, p.volume, p.volume_measure, \n",
    "CASE WHEN p.volume_measure = '9LC' THEN 0.11111111 ELSE 1 END as factor, \n",
    "p.country_id, p.tier_iid, t.name as tier_name, p.type, \n",
    "CASE WHEN p.type = 1 THEN 'Product' WHEN p.type = 2 THEN 'Promotion' end as type_name, \n",
    "p.brand_id, p.sub_brand_id, sb.sub_brand_name, p.product_category_id, p.segment_id, s.name as segment_name, s.description as segment_description, p.manufacturer, p.history, p.quantity_per_case, p.primary_UOM, p.secondary_UOM, p.content, p.start_date, p.end_date, image_url  \n",
    "FROM Staging.VW_CAT_PRODUCT p \n",
    "LEFT OUTER JOIN Staging.VW_CAT_TIER t on p.tier_iid = t.id \n",
    "LEFT JOIN Staging.VW_CAT_SEGMENT s on p.segment_id = s.id \n",
    "LEFT JOIN Staging.VW_CAT_PRODUCT_TYPE pt on p.product_type = pt.id \n",
    "LEFT JOIN Staging.VW_CAT_SUB_BRAND sb on p.sub_brand_id = sb.sub_brand_id\n",
    "\"\"\").load()\n",
    "\n",
    "df_dim_product.createOrReplaceTempView('PRODUCT')\n",
    "\n",
    "df_product_category = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_BI_CAT_PRODUCT_CATEGORY\").load()\n",
    "\n",
    "df_product_category.createOrReplaceTempView('PRODUCT_CATEGORY')\n",
    "\n",
    "df_super_category = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"SELECT id, name, active, CASE WHEN include_in_lc_reports=1 THEN 'Y' ELSE 'N' END as super_category_9LC_calculation FROM Staging.VW_BI_SUPER_CATEGORY\"\"\").load()\n",
    "\n",
    "df_super_category.createOrReplaceTempView('SUPER_CATEGORY')\n",
    "\n",
    "df_dim_all_product = spark.sql(\"\"\"\n",
    "SELECT p.id, p.name, p.active, p.sku, p.ean, p.product_type, p.product_type_name, p.product_type_active, p.volume, p.volume_measure, p.factor, p.country_id, p.tier_iid, tier_name, type, type_name, brand_id, sub_brand_id, sub_brand_name, p.segment_id, p.segment_name, p.segment_description, p.manufacturer, p.history, p.quantity_per_case, p.primary_UOM, p.secondary_UOM, p.content, p.start_date, p.end_date, p.product_category_id as category_id, pc.name as category_name, \n",
    "CASE WHEN p.product_category_id is not null AND p.volume_measure is not null THEN CONCAT(pc.name,' - ',p.volume_measure) ELSE null END as category_measure,\n",
    "pc.active as category_acive, pc.super_category_id as super_category_id, sc.name as super_category_name, sc.active as super_category_active, sc.super_category_9LC_calculation, image_url\n",
    "FROM PRODUCT p \n",
    "  LEFT JOIN PRODUCT_CATEGORY pc ON p.product_category_id = pc.id \n",
    "  LEFT JOIN SUPER_CATEGORY sc ON pc.super_category_id = sc.id\n",
    "\"\"\")\n",
    "\n",
    "df_dim_all_product.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Product]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n",
    "\n",
    "#display(df_dim_all_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9180c9d-ff39-4111-b85f-f7ce6f739624",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Product_Chain: VW_PRODUCT_CHAIN\n",
    "\n",
    "df_dim_product_chain = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_PRODUCT_CHAIN\").load()\n",
    "\n",
    "df_dim_product_chain.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Product_Chain]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6243ba3b-0637-4494-a4de-32032f5e9189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Member (CPG): VW_BI_CAT_MEMBER\n",
    "\n",
    "df_dim_member = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_CAT_MEMBER\").load()\n",
    "\n",
    "df_dim_member.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Member]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92dd6862-ebec-4d36-b93a-d21697007c50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Business: join views VW_BI_BUSINESS_DASHBOARD, VW_CAT_IMAGE_LEVEL, VW_CAT_CHANNEL, VW_CAT_SUB_CHANNEL, VW_BI_CITY, VW_BI_CHAIN_BUSINESS_DASHBOARD\n",
    "\n",
    "df_business = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\", \"\"\"SELECT b.id, b.name, b.channel_id, b.sub_channel_id, b.image_level_id,  b.city_id, b.country_id, b.position_id, b.active,\n",
    "CASE b.active\n",
    "  WHEN -1 THEN 'Pending'\n",
    "  WHEN 0 THEN 'Inactive'\n",
    "  WHEN 1 THEN 'Active' \n",
    "  WHEN 2 THEN 'Rejected'\n",
    "  WHEN 3 THEN 'Closed' \n",
    "  ELSE null \n",
    "END as business_status, b.reporting, invitation_code, created_at, updated_at, first_order_date, last_order_date \n",
    "FROM Staging.VW_BI_BUSINESS_DASHBOARD b \n",
    "\"\"\").load()\n",
    "\n",
    "df_business_active_data = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\", \"\"\"SELECT *,\n",
    "case when active = 1 then cast ('9999-12-31' as date)\n",
    "     when active_new = 1 then eomonth((SELECT max(created_at) FROM companyDummy.Fact_Order f where f.business_id = T1.id )) \n",
    "\t end as active_end_date\n",
    "FROM \n",
    "(\n",
    "select b.id, \n",
    "\tactive, \n",
    "\tcase when active = 1 OR exists (select 1 from Staging.VW_ORDER_DASHBOARD f where b.id = f.business ) then 1 else 0 end as active_new, cast(created_at as Date) as active_start_date\n",
    "from Staging.VW_BI_BUSINESS_DASHBOARD b\n",
    ") T1\n",
    "\"\"\").load()\n",
    "\n",
    "df_image_level = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\", \"Staging.VW_CAT_IMAGE_LEVEL\").load()\n",
    "\n",
    "df_channel = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\", \"Staging.VW_CAT_CHANNEL\").load()\n",
    "\n",
    "# This view classifies channels into groups according to given definition \n",
    "\n",
    "df_channel_group = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT id AS channel_id,\n",
    "CASE \n",
    "\tWHEN id IN (2, 9, 10, 11, 14, 16, 17, 18, 20, 21, 23, 24) THEN 'On Trade'\n",
    "\tWHEN id IN (1, 12, 15, 19, 22) THEN 'Tradi Off.Trade'\n",
    "\tWHEN id IN (4, 25) THEN 'Tier-2 WHS'\n",
    "\tWHEN id IN (13) THEN 'Online sellers'\n",
    "\tELSE 'OTHERS'\n",
    "END AS channel_group,\n",
    "CASE \n",
    "\tWHEN id IN (2, 9, 10, 11, 14, 16, 17, 18, 20, 21, 23, 24) THEN 1\n",
    "\tWHEN id IN (1, 12, 15, 19, 22) THEN 2\n",
    "\tWHEN id IN (4, 25) THEN 3\n",
    "\tWHEN id IN (13) THEN 4\n",
    "\tELSE 5\n",
    "END AS group_order\n",
    "from Staging.VW_CAT_CHANNEL \"\"\").load()\n",
    "\n",
    "df_sub_channel = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\", \"Staging.VW_CAT_SUB_CHANNEL\").load()\n",
    "\n",
    "df_city = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\", \"Staging.VW_BI_CITY\").load()\n",
    "\n",
    "df_chain_business = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_BI_CHAIN_BUSINESS_DASHBOARD\").load()\n",
    "\n",
    "\n",
    "df_business.createOrReplaceTempView('BUSINESS')\n",
    "df_business_active_data.createOrReplaceTempView('BUSINESS_ACTIVE_DATA')\n",
    "df_image_level.createOrReplaceTempView('IMAGE_LEVEL')\n",
    "df_channel.createOrReplaceTempView('CHANNEL')\n",
    "df_channel_group.createOrReplaceTempView('CHANNEL_GROUP')\n",
    "df_sub_channel.createOrReplaceTempView('SUB_CHANNEL')\n",
    "df_city.createOrReplaceTempView('CITY')\n",
    "df_chain_business.createOrReplaceTempView('CHAIN_BUSINESS')\n",
    "\n",
    "\n",
    "df_dim_business = spark.sql(\"\"\"\n",
    "SELECT b.id, b.name, b.channel_id, c.name as channel_name, c.description as channel_description, b.sub_channel_id, sc.name as sub_channel_name, sc.description as sub_channel_description, cg.channel_group, cg.group_order as channel_group_order, b.image_level_id, i.name as image_level_name, b.city_id, ci.name as city_name, ci.state as state, b.country_id,b.position_id, b.active, b.business_status, b.reporting, created_at, updated_at, first_order_date, last_order_date, cb.business_type, invitation_code, \n",
    "CONCAT('R',LEFT(created_at,7)) as registered_month, \n",
    "CASE \n",
    "WHEN MONTH(created_at) BETWEEN 7 AND 9 THEN CONCAT('RFY',YEAR(created_at)-1999,'-Q1')\n",
    "WHEN MONTH(created_at) BETWEEN 10 AND 12 THEN CONCAT('RFY',YEAR(created_at)-1999,'-Q2')\n",
    "WHEN MONTH(created_at) BETWEEN 1 AND 3 THEN CONCAT('RFY',YEAR(created_at)-2000,'-Q3')\n",
    "WHEN MONTH(created_at) BETWEEN 4 AND 6 THEN CONCAT('RFY',YEAR(created_at)-2000,'-Q4')\n",
    "END as registered_qtr,\n",
    "datediff(current_date(),created_at) as days_since_reg,\n",
    "datediff(current_date(),last_order_date) as days_since_last_order,\n",
    "acd.active_new, acd.active_start_date, acd.active_end_date\n",
    "FROM BUSINESS b \n",
    "  LEFT JOIN IMAGE_LEVEL i ON b.image_level_id = i.id \n",
    "  LEFT JOIN CHANNEL c ON b.channel_id = c.id \n",
    "  LEFT JOIN CHANNEL_GROUP cg ON b.channel_id = cg.channel_id \n",
    "  LEFT JOIN SUB_CHANNEL sc ON b.sub_channel_id = sc.id \n",
    "  LEFT JOIN CITY ci ON b.city_id = ci.id \n",
    "  LEFT JOIN \n",
    "      (\n",
    "      SELECT business_id, MAX(business_type_description) as business_type\n",
    "      FROM CHAIN_BUSINESS\n",
    "      WHERE business_type is not null\n",
    "      GROUP BY business_id\n",
    "      ) cb ON b.id = cb.business_id AND b.country_id = 13      \n",
    "  LEFT JOIN BUSINESS_ACTIVE_DATA acd ON b.id = acd.id\n",
    "\"\"\")\n",
    "\n",
    "#display(df_dim_business)\n",
    "\n",
    "df_dim_business.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Business]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "141ad23d-b666-4265-a0dc-c1fae6fa23b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_User: VW_BI_USER join VW_CAT_POSITION\n",
    "\n",
    "df_dim_user = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"SELECT b.id, b.position_id, c.name as position_name, b.country_id, b.sales_rep as sales_rep_id, email, phone, push_notification, email_notification, sms_notification, whatsapp_notification, created_at, registration_date, last_login_date FROM Staging.VW_BI_USER b LEFT JOIN Staging.VW_CAT_POSITION c ON b.position_id = c.id \"\"\").load()\n",
    "\n",
    "#display(df_dim_user)\n",
    "\n",
    "df_dim_user.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_User]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81f9a6b5-de03-4daa-97de-4805b3f61e01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Sales_rep: VW_BI_SALES_REP, VW_BI_SALES_REP_BUSINESS, VW_BI_BUSINESS_DASHBOARD, VW_CAT_COUNTRY\n",
    "\n",
    "df_dim_sales_rep = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT \n",
    "id,\n",
    "email,\n",
    "chain_id,\n",
    "name,\n",
    "last_name,\n",
    "CASE\n",
    "    WHEN last_name is not null THEN CONCAT(name,' ',last_name)\n",
    "    ELSE name\n",
    "END as sales_rep\n",
    "FROM Staging.VW_BI_SALES_REP SR\n",
    "\"\"\").load()\n",
    "\n",
    "df_dim_sales_rep.createOrReplaceTempView('SALES_REP')\n",
    "\n",
    "# sales_rep language depending on the country of one of its businesses\n",
    "\n",
    "df_dim_sales_rep_business = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_BI_SALES_REP_BUSINESS\").load()\n",
    "\n",
    "df_dim_sales_rep_business.createOrReplaceTempView('SALES_REP_BUSINESS')\n",
    "\n",
    "df_dim_business = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\", \"Staging.VW_BI_BUSINESS_DASHBOARD\").load()\n",
    "\n",
    "df_dim_business.createOrReplaceTempView('BUSINESS')\n",
    "\n",
    "df_dim_country = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"SELECT id,\n",
    "CASE\n",
    "  WHEN name IN ('Colombia','España','Mexico') THEN 'es-ES'\n",
    "  ELSE 'en-US'\n",
    "END AS language\n",
    "FROM Staging.VW_CAT_COUNTRY\"\"\").load()\n",
    "\n",
    "df_dim_country.createOrReplaceTempView('COUNTRY')\n",
    "\n",
    "df_dim_sales_rep = spark.sql(\"\"\"\n",
    "SELECT SR.*, case when c.language is null then 'en-US' else c.language end as language\n",
    "FROM SALES_REP SR\n",
    "LEFT JOIN\n",
    "(\n",
    "SELECT SRB.sales_rep_id, MIN(SRB.business_id) as business_id\n",
    "FROM SALES_REP_BUSINESS SRB\n",
    "GROUP BY SRB.sales_rep_id\n",
    ") T1\n",
    "ON SR.id = T1.sales_rep_id\n",
    "LEFT JOIN BUSINESS B\n",
    "ON T1.business_id = B.id\n",
    "LEFT JOIN COUNTRY C\n",
    "ON B.country_id = C.id\n",
    "\"\"\")\n",
    "\n",
    "#display(df_dim_sales_rep)\n",
    "\n",
    "df_dim_sales_rep.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Sales_Rep]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5327306-63d5-4f3b-8a02-1bcf4ef58fcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Chain (Wholesaler): VW_CAT_CHAIN_DASHBOARD\n",
    "\n",
    "df_dim_chain = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\",  conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\", \"\"\"SELECT id, name, active, country_id, prospects, chain_tier, chain_tier_description, created_at \n",
    "FROM Staging.VW_CAT_CHAIN_DASHBOARD \"\"\").load()\n",
    "\n",
    "df_dim_chain.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Chain]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n",
    "\n",
    "#display(df_dim_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75f79393-9dba-49b7-aa0a-ea61831d3903",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Sales_Rep_Business: VW_BI_SALES_REP_BUSINESS join VW_BI_SALES_REP\n",
    "\n",
    "df_dim_sales_rep_business = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_BI_SALES_REP_BUSINESS\").load()\n",
    "\n",
    "df_dim_sales_rep_business.createOrReplaceTempView('SALES_REP_BUSINESS')\n",
    "\n",
    "df_dim_sales_rep = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_BI_SALES_REP\").load()\n",
    "\n",
    "df_dim_sales_rep.createOrReplaceTempView('SALES_REP')\n",
    "\n",
    "#### This view was created because of a combination of business-id and chain-id where there are more than 1 sales rep\n",
    "\n",
    "df_dim_sales_rep_business = spark.sql(\"\"\"\n",
    "SELECT SRB.sales_rep_id, SRB.business_id, SR.chain_id, CONCAT(SRB.business_id,'-',SR.chain_id) as business_chain\n",
    "FROM SALES_REP_BUSINESS SRB\n",
    "  LEFT JOIN SALES_REP SR ON SRB.sales_rep_id = SR.id \n",
    "\"\"\")\n",
    "\n",
    "#display(df_dim_sales_rep_business)\n",
    "\n",
    "df_dim_sales_rep_business.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Sales_Rep_Business]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3a2e9d9-93b3-409c-a9c7-65730376b3aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Distributor: VW_CAT_DISTRIBUTION_DASHBOARD\n",
    "  \n",
    "df_dim_distribution = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_CAT_DISTRIBUTION_DASHBOARD\").load()\n",
    "\n",
    "#display(df_dim_distribution) \n",
    "\n",
    "df_dim_distribution.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Distribution]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80d17409-d66f-4cf2-a559-c151c8fac446",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Member_Chain (CPG-Wholesaler): VW_MEMBER_CHAIN_DASHBOARD\n",
    "\n",
    "df_dim_member_chain = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", \n",
    "conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_MEMBER_CHAIN_DASHBOARD\").load()\n",
    "\n",
    "# display(df_dim_member_chain)\n",
    "\n",
    "df_dim_member_chain.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Member_chain]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cdb70d9-d6ed-4e38-b26d-cfedef2db7ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Business_Chain_User: VW_BI_BUSINESS_USER_PARTNER_DASHBOARD (se anula la columna customer_type, viene siempre en 1)\n",
    "\n",
    "df_dim_business_chain_user = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"SELECT business as business_id, chain as chain_id, [user] as user_id, status, role, CONCAT(business,'-',chain) as business_chain FROM Staging.VW_BI_BUSINESS_USER_PARTNER_DASHBOARD\").load()\n",
    "\n",
    "df_dim_business_chain_user.createOrReplaceTempView('BUSINESS_CHAIN_USER')\n",
    "\n",
    "#### This view was created because of a combination of business-id and chain-id where there are more than 1 sales rep\n",
    "\n",
    "# run previous to cmd 12 and cmd 10\n",
    "\n",
    "df_dim_sales_rep_business.createOrReplaceTempView('SALES_REP_BUSINESS')\n",
    "\n",
    "df_dim_sales_rep.createOrReplaceTempView('SALES_REP')\n",
    "\n",
    "df_dim_business_chain_user = spark.sql(\"\"\"\n",
    "SELECT BCU.*, SB.sales_rep_id, S.email as sales_rep_email, \n",
    "CASE\n",
    "    WHEN S.last_name is not null THEN CONCAT(S.name,' ',S.last_name)\n",
    "    ELSE S.name\n",
    "END as sales_rep\n",
    "FROM BUSINESS_CHAIN_USER BCU\n",
    "  LEFT JOIN SALES_REP_BUSINESS SB ON BCU.business_chain = SB.business_chain\n",
    "  LEFT JOIN SALES_REP S ON SB.sales_rep_id = S.id\n",
    "\"\"\")\n",
    "\n",
    "#display(df_dim_business_chain_user)\n",
    "\n",
    "df_dim_business_chain_user.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Business_Chain_User]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df3be22b-1049-4655-aa06-b1a463e49ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Chain_Business: VW_BI_CHAIN_BUSINESS_DASHBOARD join VW_BI_BUSINESS_DASHBOARD\n",
    "\n",
    "df_dim_chain_business = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_BI_CHAIN_BUSINESS_DASHBOARD\").load()\n",
    "\n",
    "df_dim_chain_business.createOrReplaceTempView('CHAIN_BUSINESS')\n",
    "\n",
    "df_channel = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\", \"Staging.VW_CAT_CHANNEL\").load()\n",
    "\n",
    "df_channel.createOrReplaceTempView('CHANNEL')\n",
    "\n",
    "\n",
    "df_dim_business = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\", \"Staging.VW_BI_BUSINESS_DASHBOARD\").load()\n",
    "\n",
    "df_dim_business.createOrReplaceTempView('BUSINESS')\n",
    "\n",
    "\n",
    "df_dim_chain_business = spark.sql(\"\"\"\n",
    "SELECT CB.chain_id, \n",
    "CB.business_id, \n",
    "CB.business_type, \n",
    "CASE \n",
    "  WHEN CB.customer_chain_code is null THEN '0' ELSE CB.customer_chain_code\n",
    "END as business_chain_code, \n",
    "CB.business_type_description, \n",
    "B.name as business_name,\n",
    "CONCAT(\n",
    "CASE \n",
    "  WHEN CB.customer_chain_code is null THEN '0' ELSE CB.customer_chain_code\n",
    "END, '-', B.name)\n",
    "as business_code_name, \n",
    "CONCAT(CB.chain_id,'|',CB.business_id) as chain_business,\n",
    "b.channel_id as business_channel_id, ch.name as business_channel_name, ch.description as business_channel_description \n",
    "FROM CHAIN_BUSINESS CB\n",
    "LEFT OUTER JOIN BUSINESS B\n",
    "ON CB.business_id = B.id\n",
    "LEFT OUTER JOIN CHANNEL CH\n",
    "ON B.channel_id = CH.id\n",
    "\"\"\")\n",
    "\n",
    "#display(df_dim_chain_business)\n",
    "\n",
    "df_dim_chain_business.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Chain_Business]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d046e26-c083-400b-802c-aefb1fccf977",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Dim_Country: VW_CAT_COUNTRY\n",
    "\n",
    "df_dim_country = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"SELECT id, name, active, app_logo, currency_code, nps_min, nps_max, nps_yellow, nps_green,\n",
    "CASE\n",
    "  WHEN name = 'Mexico' THEN 'MX'\n",
    "  WHEN name = 'Singapore' THEN 'SG'\n",
    "  END AS country_code_GA, \n",
    "CASE\n",
    "  WHEN name IN ('Colombia','España','Mexico') THEN 'es-ES'\n",
    "  ELSE 'en-US'\n",
    "END AS language,\n",
    "CASE\n",
    "  WHEN name = 'Colombia' THEN 'M'\n",
    "  ELSE 'K'\n",
    "END as Unit_Measure_GMV,\n",
    "CASE\n",
    "  WHEN name = 'Colombia' THEN 1000000\n",
    "  ELSE 1000\n",
    "END as Local_Currency_Divisor  \n",
    "FROM Staging.VW_CAT_COUNTRY\"\"\").load()\n",
    "\n",
    "df_dim_country.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Country]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n",
    "\n",
    "#display(df_dim_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cde3eb6-11d8-4fbe-a8f9-fcb95f133c26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Promo_Channel: VW_PROMO_CHANNEL\n",
    "\n",
    "df_dim_promo_channel = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_PROMO_CHANNEL\").load()\n",
    "\n",
    "df_dim_promo_channel.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Promo_Channel]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d61ecf9-e492-4dce-8d3b-d1abe07cff9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Promo_SubChannel: VW_PROMO_SUBCHANNEL\n",
    "\n",
    "df_dim_promo_subchannel = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_PROMO_SUBCHANNEL\").load()\n",
    "\n",
    "df_dim_promo_subchannel.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Promo_SubChannel]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1b62055-12de-4616-af38-683827663dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Promo_Image_level: VW_PROMO_IMAGE_LEVEL\n",
    "\n",
    "df_dim_promo_image_level = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_PROMO_IMAGE_LEVEL\").load()\n",
    "\n",
    "df_dim_promo_image_level.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Promo_Image_Level]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dee6053-3480-4576-9e01-c24235f344ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Promo_Business: VW_PROMO_BUSINESS\n",
    "\n",
    "df_dim_promo_business = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_PROMO_BUSINESS\").load()\n",
    "\n",
    "df_dim_promo_business.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Promo_Business]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ca87d2a-70c2-44a2-84ca-9dbad4f0c11b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Promo_Business_Type: VW_PROMO_BUSINESS_TYPE\n",
    "\n",
    "df_dim_promo_business_type = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_PROMO_BUSINESS_TYPE\").load()\n",
    "\n",
    "df_dim_promo_business_type.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Promo_Business_Type]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65de8f52-4c15-45a9-8228-0a47bd921b11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Promo_by_business: VW_BI_BUSINESS_DASHBOARD, VW_PROMO_BUSINESS, VW_PROMO_CHANNEL, VW_PROMO_SUBCHANNEL\n",
    "\n",
    "df_business = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\", \"\"\"SELECT id, channel_id, sub_channel_id\n",
    "FROM Staging.VW_BI_BUSINESS_DASHBOARD\"\"\").load()\n",
    "\n",
    "df_promo_business = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\", \"Staging.VW_PROMO_BUSINESS\").load()\n",
    "\n",
    "df_promo_channel = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\", \"Staging.VW_PROMO_CHANNEL\").load()\n",
    "\n",
    "df_promo_subchannel = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\", \"Staging.VW_PROMO_SUBCHANNEL\").load()\n",
    "\n",
    "df_business.createOrReplaceTempView('BUSINESS') \n",
    "df_promo_business.createOrReplaceTempView('PROMO_BUSINESS') \n",
    "df_promo_channel.createOrReplaceTempView('PROMO_CHANNEL')\n",
    "df_promo_subchannel.createOrReplaceTempView('PROMO_SUBCHANNEL')\n",
    "\n",
    "df_promo_by_business = spark.sql(\"\"\"\n",
    "SELECT business_id, \n",
    "CASE WHEN channel_id IS NULL THEN 0 ELSE channel_id END as channel_id, \n",
    "CASE WHEN sub_channel_id IS NULL THEN 0 ELSE sub_channel_id END as sub_channel_id, \n",
    "CASE WHEN product_id IS NULL THEN 0 ELSE product_id END as product_id\n",
    "FROM\n",
    "(\n",
    "SELECT id as business_id, b.channel_id, b.sub_channel_id, pb.product_id\n",
    "FROM BUSINESS b\n",
    "INNER JOIN\n",
    "\tPROMO_BUSINESS pb\n",
    "ON b.id = pb.business_id\n",
    "UNION\n",
    "SELECT id as business_id, b.channel_id, sub_channel_id, pc.product_id\n",
    "FROM BUSINESS b\n",
    "INNER JOIN\n",
    "\tPROMO_CHANNEL pc\n",
    "ON b.channel_id = pc.channel_id\n",
    "UNION\n",
    "SELECT id as business_id, b.channel_id, sub_channel_id, ps.product_id\n",
    "FROM BUSINESS b\n",
    "INNER JOIN\n",
    "\tPROMO_SUBCHANNEL ps\n",
    "ON b.sub_channel_id= ps.subchannel_id\n",
    ") T1\n",
    "\"\"\")\n",
    "\n",
    "# display(df_promo_by_business)\n",
    "\n",
    "df_promo_by_business.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Promo_by_Business]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c0c0066-d3ec-475b-a8f1-d8e09eacf7b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Promo_Product\n",
    "\n",
    "df_dim_promo_product = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT *, \n",
    "  CASE \n",
    "    WHEN COUNT(*) OVER (PARTITION BY promo_id) > 1 then 'Mixed Bundle' \n",
    "    WHEN quantity > 1 THEN 'Multi Buy' \n",
    "    ELSE 'Discount' \n",
    "  END AS promo_type,\n",
    "  ROW_NUMBER() OVER (PARTITION BY promo_id ORDER BY quantity DESC) AS rn\n",
    "FROM Staging.VW_PROMO_PRODUCT\n",
    "\"\"\").load()\n",
    "\n",
    "#display(df_dim_promo_product)\n",
    "\n",
    "df_dim_promo_product.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Promo_Product]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8f0d3f3-8fcc-4504-8fbf-3dcd3b87c936",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# New Fact_Order: VW_BI_ORDER_DASHBOARD, VW_BI_RATE_VIEW, VW_SALES_REP, VW_SALES_REP_BUSINESS\n",
    "# Asignar sales rep a ordenes que no lo tienen (con el primer sales rep que aparece para una combinacion business-chain)\n",
    "\n",
    "df_fact_order = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"SELECT o.id,o.client_order_number,o.chain_id,o.business as business_id,\n",
    "user_id,u.sales_rep as user_sales_rep_id,o.distributor_id,o.country_id,o.status,\n",
    "CASE\n",
    "  WHEN o.status in ('cancelled', 'not_approved') THEN 0\n",
    "  ELSE 1\n",
    "END as valid,\n",
    "original_created_at, o.created_at, o.updated_at, o.observation, o.updated_by, o.customer, o.day_of_preference, o.delivery_cost\n",
    "FROM Staging.VW_ORDER_DASHBOARD as o \n",
    "LEFT JOIN Staging.VW_BI_USER as u\n",
    "ON o.user_id = u.id\n",
    "\"\"\").load()\n",
    "\n",
    "df_fact_order.createOrReplaceTempView('FACT_ORDER')\n",
    "\n",
    "df_fact_rate = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT id_country as country_id, calendar_year, calendar_month, rate, \n",
    "id_country + '|' + convert(char(6),(calendar_year * 100 + calendar_month)) as key_rate\n",
    "FROM Staging.VW_BI_RATE_VIEW\n",
    "--WHERE rate IS NOT null and rate != 0\n",
    "\"\"\").load()\n",
    "\n",
    "df_fact_rate.createOrReplaceTempView('RATE')\n",
    "\n",
    "# Assign sales rep_id based on the first sales_rep that corresponds to the chain-business\n",
    "df_business_chain_sales_rep=spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT SR.chain_id, SRB.business_id, MIN(SR.id) AS sales_rep_id\n",
    "FROM Staging.VW_BI_SALES_REP SR\n",
    "INNER JOIN Staging.VW_BI_SALES_REP_BUSINESS SRB ON SR.id = SRB.sales_rep_id\n",
    "GROUP BY SR.chain_id, SRB.business_id\n",
    "\"\"\").load()\n",
    "\n",
    "df_business_chain_sales_rep.createOrReplaceTempView('SALESREP_BUSINESS_CHAIN')\n",
    "\n",
    "#display(df_business_chain_sales_rep)\n",
    "\n",
    "df_query_lines = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_origin']).option(\"driver\", conf['jdbcDriver_origin']).option(\"user\", conf['jdbcUsername_origin']).option(\"password\", conf['jdbcPassword_origin']).option(\"query\",\"\"\"\n",
    "SELECT [order] as order_id, \n",
    "COUNT(*) as total_lines,\n",
    "SUM(CASE WHEN status = 'cancelled' THEN 1 ELSE 0 END) as total_cancelled_lines,\n",
    "SUM(CASE WHEN status in ('cancelled', 'not_approved', 'returned') THEN 0 ELSE current_quantity * current_unit_price - discount END) as total_amount,\n",
    "SUM(CASE WHEN status = 'cancelled' THEN current_quantity * current_unit_price - discount ELSE 0 END) as cancelled_amount\n",
    "FROM VW_ORDER_LINE_DASHBOARD \n",
    "GROUP BY [order]\n",
    "\"\"\").load()\n",
    "\n",
    "df_query_lines.createOrReplaceTempView('QUERY_LINES')\n",
    "\n",
    "df_fact_order = spark.sql(\"\"\"\n",
    "SELECT o.*, concat(o.country_id,'|',year(o.created_at)*100 + month(o.created_at)) as key_rate, r.rate, \n",
    "CASE WHEN o.user_sales_rep_id IS NOT NULL THEN o.user_sales_rep_id ELSE sbc.sales_rep_id END as sales_rep_id, \n",
    "concat(o.business_id,'-',o.chain_id) as business_chain, ol.total_lines, round(ol.total_amount,2) as total_amount,\n",
    "CASE \n",
    "  WHEN ol.total_cancelled_lines > 0 AND ol.total_cancelled_lines <> ol.total_lines THEN 'Partial'\n",
    "  WHEN ol.total_cancelled_lines > 0 AND ol.total_cancelled_lines = ol.total_lines THEN 'Total'\n",
    "END as cancellation_status,\n",
    "ol.total_cancelled_lines, ol.cancelled_amount,\n",
    "lag(o.created_at) over (partition by o.chain_id,o.business_id order by o.id) as previous_chain_business_order_date,\n",
    "datediff(o.created_at,lag(o.created_at) over (partition by o.chain_id,o.business_id order by o.id)) as days_from_last_order\n",
    "FROM FACT_ORDER o \n",
    "LEFT OUTER JOIN RATE r ON concat(o.country_id,'|',year(o.created_at)*100 + month(o.created_at)) = r.key_rate \n",
    "LEFT OUTER JOIN SALESREP_BUSINESS_CHAIN sbc ON o.business_id = sbc.business_id AND o.chain_id = sbc.chain_id\n",
    "LEFT OUTER JOIN QUERY_LINES ol ON o.id = ol.order_id\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "#display(df_fact_order)\n",
    "\n",
    "df_fact_order.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fact_Order]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaea8a8a-4515-4c01-b12d-2587e5136b63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# New Fact_order_line table (original rows from view VW_ORDER_LINE_DASHBOARD, that's showing promo products + \n",
    "# transformed lines of promo_products by the products included in the promo\n",
    "\n",
    "#\n",
    "# Original_order_line: VW_ORDER_LINE_DASHBOARD\n",
    "#\n",
    "\n",
    "df_original_order_line = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT ol.line_number, CONVERT(NVARCHAR(MAX),ol.id) as id_surrogate,\n",
    "ol.product_id, ol.current_quantity, ol.current_unit_price, ol.delivery_date, ol.invoice_number, ol.[status], \n",
    "CASE \n",
    "WHEN o.country_id = '13' and YEAR(ol.created_at) <= 2022 THEN 1.07\n",
    "WHEN o.country_id = '13' and YEAR(ol.created_at) > 2022 THEN 1.08 \n",
    "ELSE 1 \n",
    "END AS excise,\n",
    "CASE\n",
    "WHEN ol.[status] in ('cancelled', 'not_approved', 'returned') THEN 0\n",
    "ELSE 1\n",
    "END as valid,\n",
    "CASE\n",
    "WHEN ol.[status] in ('cancelled', 'not_approved', 'returned') THEN 0\n",
    "ELSE ol.current_quantity\n",
    "END as current_quantity_final,\n",
    "CASE\n",
    "WHEN ol.[status] in ('cancelled', 'not_approved', 'returned') THEN 0\n",
    "ELSE ol.current_quantity * ol.current_unit_price - ol.discount\n",
    "END as line_amount,\n",
    "CASE WHEN ol.[status] = 'cancelled' THEN ol.current_quantity ELSE 0 END as cancelled_quantity,\n",
    "CASE WHEN ol.[status] = 'cancelled' THEN ol.current_quantity * ol.current_unit_price - ol.discount ELSE 0 END as cancelled_amount,\n",
    "CASE WHEN ol.[status] = 'cancelled' THEN cancellation_id ELSE NULL END as cancellation_id, \n",
    "ol.updated_at, ol.updated_by, ol.[order], o.country_id, ol.uom, ol.id, ol.observation, ol.created_at,\n",
    "ol.payment_date, ol.invoice_date, ol.discount, ol.taxes, ol.presentation, ol.presentation_quantity, ol.cost_per_unit,\n",
    "0 as line_transformed,\n",
    "CASE WHEN Promo.promo_id IS NULL THEN 'Normal Product' ELSE 'Promo Product' END as product_flag,\n",
    "null as promo_row,\n",
    "null as promo_id,\n",
    "null as promo_product_id,\n",
    "CONVERT(NVARCHAR(MAX),null) as promo_type\n",
    "FROM Staging.VW_ORDER_LINE_DASHBOARD as ol \n",
    "JOIN Staging.VW_ORDER_DASHBOARD AS o ON ol.[order]=o.id\n",
    "LEFT JOIN (SELECT DISTINCT promo_id FROM Staging.VW_PROMO_PRODUCT) Promo ON ol.product_id = Promo.promo_id\n",
    "\"\"\").load()\n",
    "\n",
    "df_original_order_line.createOrReplaceTempView('ORIGINAL_FACT_ORDER_LINE')\n",
    "\n",
    "#display(df_original_order_line)\n",
    "\n",
    "#\n",
    "# End original_order_line: VW_ORDER_LINE_DASHBOARD\n",
    "#\n",
    "\n",
    "#\n",
    "# Transformed_order_line: VW_ORDER_LINE_DASHBOARD join VW_PROMO_PRODUCT \n",
    "#\n",
    "\n",
    "df_dim_promo_product = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT *, \n",
    "  CASE \n",
    "    WHEN COUNT(*) OVER (PARTITION BY promo_id) > 1 then 'Mixed Bundle' \n",
    "    WHEN quantity > 1 THEN 'Multi Buy' \n",
    "    ELSE 'Discount' \n",
    "  END AS promo_type,\n",
    " \tp.volume as promo_product_volume,\n",
    "\tp.volume_measure as promo_product_volume_measure\n",
    "FROM Staging.VW_PROMO_PRODUCT PP\n",
    "  INNER JOIN Staging.VW_CAT_PRODUCT P ON pp.product_id = p.id \n",
    "\"\"\").load()\n",
    "\n",
    "df_dim_promo_product.createOrReplaceTempView('PROMO_PRODUCT')\n",
    " \n",
    "df_transformed_order_line = spark.sql(\"\"\"\n",
    "SELECT \n",
    "\tol.line_number,\n",
    "\tconcat(ol.id,'/',rn) as id_surrogate,\n",
    "\tdp.product_id as product_id,\n",
    "  dp.quantity * current_quantity as current_quantity,\n",
    "  dp.quantity * current_quantity_final as current_quantity_final,\n",
    "\tcase \n",
    "\t\twhen dp.quantity = 0 then 0\n",
    "    when rn = 1 then ol.current_unit_price / dp.quantity \n",
    "    else null \n",
    "  end as current_unit_price, \n",
    "\tdelivery_date,\n",
    "\tinvoice_number,\n",
    "\tstatus,\n",
    "\tvalid,\n",
    " \tcase when rn = 1 then ol.line_amount else null end as line_amount,\n",
    " \tcase when rn = 1 then ol.cancelled_amount else null end as cancelled_amount,\n",
    "\tdp.quantity * ol.cancelled_quantity as cancelled_quantity,\n",
    "\tcancellation_id,\n",
    "\tupdated_at,\n",
    "\tupdated_by,\n",
    "\torder,\n",
    "\tol.country_id,\n",
    " \tcase when rn = 1 then ol.uom else null end as uom,\n",
    "  ol.id,\n",
    "\tobservation, \n",
    "\tcreated_at,\n",
    "\tpayment_date,\n",
    "\tinvoice_date,\n",
    " \tcase when rn = 1 then ol.discount else null end as discount, \n",
    " \tcase when rn = 1 then ol.taxes else null end as taxes, \n",
    "  ol.presentation,\n",
    "  ol.presentation_quantity, \n",
    " \tcase \n",
    "\t\twhen dp.quantity = 0 then 0\n",
    "\t\twhen rn = 1 then cost_per_unit / dp.quantity \n",
    "    else null\n",
    "  end as cost_per_unit, \n",
    "\texcise,\n",
    "\t-- Below data of products in promos\n",
    "\trn as promo_row,\n",
    "\tdp.promo_id,\n",
    "\tdp.promo_type,\n",
    "\tdp.product_id as promo_product_id,\n",
    "\t1 as line_transformed,\n",
    "  'Promo Normal Product' as product_flag\n",
    "FROM ORIGINAL_FACT_ORDER_LINE ol\n",
    "INNER JOIN\n",
    "(\n",
    "SELECT *,\n",
    "    ROW_NUMBER() OVER (PARTITION BY promo_id ORDER BY quantity DESC) AS rn\n",
    "    FROM PROMO_PRODUCT\n",
    ") dp ON ol.product_id = dp.promo_id\n",
    "\"\"\")\n",
    "\n",
    "df_transformed_order_line.createOrReplaceTempView('TRANSFORMED_ORDER_LINE')\n",
    "\n",
    "#display(df_transformed_order_line)\n",
    "\n",
    "#\n",
    "# End Transformed_order_line: VW_ORDER_LINE_DASHBOARD join VW_PROMO_PRODUCT \n",
    "#\n",
    "\n",
    "#\n",
    "# fact_order_line_v2: append original + transformed order lines\n",
    "#\n",
    "\n",
    "df_fact_order_line_v2 = spark.sql(\"\"\"\n",
    "select line_number, id_surrogate, product_id, current_quantity, current_unit_price, delivery_date, invoice_number, status, excise,\n",
    "valid, current_quantity_final, line_amount, cancelled_quantity, cancelled_amount, cancellation_id, updated_at, updated_by,\n",
    "order, country_id, uom, id, observation, created_at, payment_date, invoice_date, discount, taxes, presentation, presentation_quantity,\n",
    "cost_per_unit, line_transformed, product_flag, promo_row, promo_id, promo_product_id, promo_type\n",
    "from TRANSFORMED_ORDER_LINE\n",
    "union all\n",
    "select line_number, id_surrogate, product_id, current_quantity, current_unit_price, delivery_date, invoice_number, status, excise,\n",
    "valid, current_quantity_final, line_amount, cancelled_quantity, cancelled_amount, cancellation_id, updated_at, updated_by,\n",
    "order, country_id, uom, id, observation, created_at, payment_date, invoice_date, discount, taxes, presentation, presentation_quantity,\n",
    "cost_per_unit, line_transformed, product_flag, promo_row, promo_id, promo_product_id, promo_type\n",
    "from ORIGINAL_FACT_ORDER_LINE\n",
    "\"\"\")\n",
    "\n",
    "df_fact_order_line_v2.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fact_Order_Line]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n",
    "\n",
    "\n",
    "#\n",
    "# End fact_order_line: append original + transformed order lines\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d095a7fe-0918-44ed-8955-0b304a7fc982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dim_Hours_Order\n",
    "\n",
    "df_dim_Hours_Order = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_origin']).option(\"driver\", conf['jdbcDriver_origin']).option(\"user\", conf['jdbcUsername_origin']).option(\"password\", conf['jdbcPassword_origin']).option(\"query\",\"\"\"\n",
    "SELECT 0 as Hourid, '00 to 01' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' UNION\n",
    "SELECT 1 as Hourid, '01 to 02' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' UNION\n",
    "SELECT 2 as Hourid, '02 to 03' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' UNION\n",
    "SELECT 3 as Hourid, '03 to 04' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' UNION\n",
    "SELECT 4 as Hourid, '04 to 05' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' UNION\n",
    "SELECT 5 as Hourid, '05 to 06' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' UNION\n",
    "SELECT 6 as Hourid, '06 to 07' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' UNION\n",
    "SELECT 7 as Hourid, '07 to 08' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' UNION\n",
    "SELECT 8 as Hourid, '08 to 09' as HourRange, 'MORNING' as 'HourDescription', 2 as 'HourDescriptionOrder' UNION\n",
    "SELECT 9 as Hourid, '09 to 10' as HourRange, 'MORNING' as 'HourDescription', 2 as 'HourDescriptionOrder' UNION\n",
    "SELECT 10 as Hourid, '10 to 11' as HourRange, 'MORNING' as 'HourDescription', 2 as 'HourDescriptionOrder' UNION\n",
    "SELECT 11 as Hourid, '11 to 12' as HourRange, 'MORNING' as 'HourDescription', 2 as 'HourDescriptionOrder' UNION\n",
    "SELECT 12 as Hourid, '12 to 13' as HourRange, 'MORNING' as 'HourDescription', 2 as 'HourDescriptionOrder' UNION\n",
    "SELECT 13 as Hourid, '13 to 14' as HourRange, 'AFTERNOON' as 'HourDescription', 3 as 'HourDescriptionOrder' UNION\n",
    "SELECT 14 as Hourid, '14 to 15' as HourRange, 'AFTERNOON' as 'HourDescription', 3 as 'HourDescriptionOrder' UNION\n",
    "SELECT 15 as Hourid, '15 to 16' as HourRange, 'AFTERNOON' as 'HourDescription', 3 as 'HourDescriptionOrder' UNION\n",
    "SELECT 16 as Hourid, '16 to 17' as HourRange, 'AFTERNOON' as 'HourDescription', 3 as 'HourDescriptionOrder' UNION\n",
    "SELECT 17 as Hourid, '17 to 18' as HourRange, 'AFTERNOON' as 'HourDescription', 3 as 'HourDescriptionOrder' UNION\n",
    "SELECT 18 as Hourid, '18 to 19' as HourRange, 'AFTERNOON' as 'HourDescription', 3 as 'HourDescriptionOrder' UNION\n",
    "SELECT 19 as Hourid, '19 to 20' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' UNION\n",
    "SELECT 20 as Hourid, '20 to 21' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' UNION\n",
    "SELECT 21 as Hourid, '21 to 22' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' UNION\n",
    "SELECT 22 as Hourid, '22 to 23' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' UNION\n",
    "SELECT 23 as Hourid, '23 to 24' as HourRange, 'OOO' as 'HourDescription', 1 as 'HourDescriptionOrder' \n",
    "\"\"\").load()\n",
    "\n",
    "#display(df_dim_HoursOrder)\n",
    "\n",
    "df_dim_Hours_Order.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Hours_Order]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d85665af-7739-4d80-8158-99f42235df8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fact_NPS_Result: VW_NPS_RESULT_DASHBOARD \n",
    " \n",
    "df_dim_chain = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\",  conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\", \"\"\"SELECT id, name FROM Staging.VW_CAT_CHAIN_DASHBOARD \"\"\").load()\n",
    " \n",
    "df_dim_chain.createOrReplaceTempView('WHS')\n",
    " \n",
    "# display(df_dim_chain)\n",
    " \n",
    "df_nps = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"SELECT survey_start_date, survey_end_date, chain_id, business_id, score, \n",
    "CASE\n",
    "  WHEN score <= 6 THEN 'Detractor'\n",
    "  WHEN score <= 8 THEN 'Passive'\n",
    "  ELSE 'Promoter'\n",
    "END AS category,\n",
    "date, country_id, order_id, comment \n",
    "FROM Staging.VW_NPS_RESULT_DASHBOARD\n",
    "WHERE score > 0\"\"\").load()\n",
    "\n",
    "df_nps.createOrReplaceTempView('NPS')\n",
    "\n",
    "df_fact_nps_result = spark.sql(\"\"\"\n",
    "SELECT survey_start_date, survey_end_date, n.chain_id, business_id, score, category, date, country_id, order_id, comment, w.name as WHS_name\n",
    "FROM NPS n\n",
    "  LEFT OUTER JOIN WHS w\n",
    "  ON n.chain_id = w.id\n",
    "\"\"\")\n",
    " \n",
    "# display(df_fact_nps_result)\n",
    " \n",
    "df_fact_nps_result.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fact_NPS_Result]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70fcf9b5-95bd-4668-a593-a7bb7bba9f21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fact_Rate: VW_BI_RATE_VIEW \n",
    "\n",
    "df_fact_rate = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT id_country as country_id, calendar_year, calendar_month, rate, \n",
    "id_country + '|' + convert(char(6),(calendar_year * 100 + calendar_month)) as key_rate\n",
    "FROM Staging.VW_BI_RATE_VIEW\n",
    "--WHERE rate IS NOT null and rate != 0\n",
    "\"\"\").load()\n",
    "\n",
    "#display(df_fact_rate)\n",
    "\n",
    "df_fact_rate.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fact_Rate]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9de56749-4660-42bd-a8c7-b2002949c7d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fact_Target: VW_BI_TARGET_VIEW\n",
    "\n",
    "df_fact_target = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT id_country as country_id, calendar_year, calendar_month, target, \n",
    "id_country + '|' + convert(char(6),(calendar_year * 100 + calendar_month)) as key_rate\n",
    "FROM Staging.VW_BI_TARGET_VIEW\"\"\").load()\n",
    "\n",
    "df_fact_target.createOrReplaceTempView('TARGET')\n",
    "\n",
    "df_fact_rate = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT id_country as country_id, calendar_year, calendar_month, rate, \n",
    "id_country + '|' + convert(char(6),(calendar_year * 100 + calendar_month)) as key_rate\n",
    "FROM Staging.VW_BI_RATE_VIEW\n",
    "\"\"\").load()\n",
    "\n",
    "df_fact_rate.createOrReplaceTempView('RATE')\n",
    "\n",
    "df_fact_target = spark.sql(\"\"\"\n",
    "SELECT t.country_id, t.calendar_year, t.calendar_month, t.target, t.key_rate,\n",
    "CASE WHEN t.calendar_month > 6 THEN t.calendar_month - 6\n",
    "ELSE t.calendar_month + 6\n",
    "END as order_month,\n",
    "cast(concat(t.calendar_year,'-',t.calendar_month,'-',1) as date) as Fecha,\n",
    "r.rate,\n",
    "t.target * r.rate as target_euros,\n",
    "t.calendar_year * 100 + t.calendar_month as Year_Month,\n",
    "CASE\n",
    "WHEN t.country_id = '13' and t.calendar_year <= 2022 THEN 1.07\n",
    "WHEN t.country_id = '13' and t.calendar_year > 2022 THEN 1.08\n",
    "ELSE 1\n",
    "END as excise\n",
    "FROM TARGET t\n",
    "  LEFT OUTER JOIN RATE r\n",
    "  ON t.key_rate = r.key_rate\n",
    "\"\"\")\n",
    "\n",
    "#display(df_fact_target)\n",
    "\n",
    "df_fact_target.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fact_Target]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bd2b198-842f-4303-aea6-c37b3b31cd40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fact_Notification_Tracking: join views VW_NOTIFICATION_DASHBOARD, VW_CART_DASHBOARD, VW_CART_LINE_DASHBOARD, VW_ORDER_DASHBOARD, VW_ORDER_LINE_DASHBOARD, VW_CAT_PRODUCT\n",
    "\n",
    "df_notif = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "    SELECT country, business_id as business, chain, [user_id], promotion_id, pro.name as product, configuration_id, noti.created_at, sent_at, opened_at\n",
    "    FROM Staging.VW_NOTIFICATION_DASHBOARD noti\n",
    "    LEFT OUTER JOIN\n",
    "        Staging.VW_CAT_PRODUCT pro\n",
    "    ON noti.promotion_id = pro.id\n",
    "\"\"\").load()\n",
    "\n",
    "df_cart = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT id, country_id, [user_id], business, chain_id, created_at as add_to_cart_at \n",
    "FROM Staging.VW_CART_DASHBOARD\n",
    "\"\"\").load()\n",
    "\n",
    "df_cart_line = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT cart, product\n",
    "FROM Staging.VW_CART_LINE_DASHBOARD\n",
    "WHERE product IS NOT null\n",
    "\"\"\").load()\n",
    "\n",
    "df_order = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT id, country_id, [user_id], business, chain_id, created_at \n",
    "FROM Staging.VW_ORDER_DASHBOARD\n",
    "\"\"\").load()\n",
    "\n",
    "df_order_line = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"\"\"\n",
    "SELECT product_id,[order] \n",
    "FROM Staging.VW_ORDER_LINE_DASHBOARD\n",
    "\"\"\").load()\n",
    "\n",
    "df_notif.createOrReplaceTempView('NOTIF')\n",
    "df_cart.createOrReplaceTempView('CART')\n",
    "df_cart_line.createOrReplaceTempView('CART_LINE')\n",
    "df_order.createOrReplaceTempView('ORDERS')\n",
    "df_order_line.createOrReplaceTempView('ORDER_LINE')\n",
    "\n",
    "df_fact_not_track = spark.sql(\"\"\"\n",
    "SELECT country, business, chain, user_id, promotion_id, product, configuration_id, created_at, sent_at, opened_at, add_to_cart_at, \n",
    "  CASE \n",
    "    WHEN bought_at > add_to_cart_at then bought_at \n",
    "    ELSE null \n",
    "  END as bought_at \n",
    "FROM\n",
    "(\n",
    "  SELECT T1.country, T1.business, T1.chain, T1.user_id, T1.promotion_id, T1.product, T1.configuration_id, T1.created_at, T1.sent_at, T1.opened_at, \n",
    "  CASE \n",
    "    WHEN T2.add_to_cart_at > T1.opened_at THEN T2.add_to_cart_at \n",
    "    ELSE null \n",
    "  END as add_to_cart_at, T3.last_date_order as bought_at\n",
    "  FROM\n",
    "    ( SELECT * FROM NOTIF ) as T1\n",
    "  LEFT OUTER JOIN\n",
    "    (\n",
    "    /* Busco ultima fecha de cada producto para cada user+business+chain en el carrito */\n",
    "    SELECT country_id, user_id, business, chain_id, product, MAX(add_to_Cart_at) as add_to_Cart_at\n",
    "    FROM \n",
    "      ( SELECT * FROM CART ) as aux1\n",
    "    INNER JOIN\n",
    "      ( SELECT * FROM CART_LINE ) as aux2\n",
    "    ON aux1.id = aux2.cart\n",
    "    GROUP BY country_id, user_id, business, chain_id, product\n",
    "    ) as T2\n",
    "  ON T1.country = T2.country_id\n",
    "  AND T1.chain = T2.chain_id\n",
    "  AND T1.business = T2.business\n",
    "  AND T1.user_id = T2.user_id\n",
    "  AND T1.promotion_id = T2.product\n",
    "  LEFT OUTER JOIN\n",
    "  (\n",
    "      /* Busco ultima fecha de compra de cada producto para cada user+business+chain */\n",
    "    SELECT country_id, user_id, business, chain_id, product_id, MAX(aux3.created_at) as last_Date_order\n",
    "    FROM\n",
    "      ( SELECT * FROM ORDERS ) as aux3\n",
    "    INNER JOIN\n",
    "      ( SELECT * FROM ORDER_LINE ) as aux4\n",
    "    ON aux3.id = aux4.order\n",
    "    GROUP BY country_id, user_id, business, chain_id, product_id\n",
    "  ) as T3\n",
    "  ON T1.country = T3.country_id AND T1.chain = T3.chain_id AND T1.business = T3.business AND T1.user_id = T3.user_id AND T1.promotion_id = T3.product_id\n",
    ") as Tmp_table \n",
    "\"\"\")\n",
    "\n",
    "#display(df_fact_not_track)\n",
    "\n",
    "df_fact_not_track.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fact_Notification_Tracking]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc87fb77-32dd-4cd3-aab7-dcb313ea60cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fact_analytics_search: VW_ANALYTICS_SEARCH_DASHBOARD\n",
    "\n",
    "df_fact_analytics_search = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_ANALYTICS_SEARCH_DASHBOARD\").load()\n",
    "\n",
    "#df_fact_analytics_search=df_fact_analytics_search.withColumn(\"created_at\",unix_timestamp(df_fact_analytics_search[\"created_at\"], \"yyyy-MM-dd HH:mm:ss\").cast(\"timestamp\"))\n",
    "\n",
    "df_fact_analytics_search.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fact_Analytics_Search]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n",
    "\n",
    "#display(df_fact_analytics_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ce2ceb2-1b3f-4f68-a606-44d93eaa9283",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Google Analytics\n",
    "\n",
    "# 29/05/24 This notebook is disabled because it produces the following error:\n",
    "# net.snowflake.client.jdbc.SnowflakeSQLException: User access disabled. Contact your local system administrator.\n",
    "\n",
    "# options = {\n",
    "#   \"sfUrl\": dbutils.secrets.get('key-vault-company-secrets', 'sf-googleanalytics-url'),\n",
    "#   \"sfUser\": dbutils.secrets.get('key-vault-company-secrets', 'sf-googleanalytics-user'),\n",
    "#   \"sfPassword\": dbutils.secrets.get('key-vault-company-secrets', 'sf-googleanalytics-password'),\n",
    "#   \"sfDatabase\": dbutils.secrets.get('key-vault-company-secrets', 'sf-googleanalytics-db'),\n",
    "#   \"sfSchema\": dbutils.secrets.get('key-vault-company-secrets', 'sf-googleanalytics-schema'),\n",
    "#   \"sfWarehouse\": dbutils.secrets.get('key-vault-company-secrets', 'sf-googleanalytics-warehouse')\n",
    "# }\n",
    "\n",
    "# df_Fact_GA = spark.read \\\n",
    "#   .format(\"snowflake\") \\\n",
    "#   .options(**options) \\\n",
    "#   .option(\"query\",  \"\"\"\n",
    "#   SELECT VISITSTARTTIME, TOTALS_TIMEONSITE, DEVICE_OPERATINGSYSTEM, DEVICE_DEVICECATEGORY, GEONETWORK_COUNTRY, GEONETWORK_CITY, \n",
    "#   HITS_PAGE_HOSTNAME, FULLVISITORID, 1 as Enabled  \n",
    "#   FROM PRLAT_PROD_DB.SCH_PRLAT_CONSUMER_GOOGLE_ANALYTICS.GOOGLE_ANALYTICS_RAW_DATA \n",
    "#   WHERE WEB_PROPERTY_ID = 'UA-99306742-7' \n",
    "#     AND \n",
    "#     (HITS_PAGE_HOSTNAME = 'app.e-anaquel.com.mx' or HITS_PAGE_HOSTNAME = 'app.company.com.sg' \n",
    "#      or HITS_PAGE_HOSTNAME = 'www.e-anaquel.com.mx')\"\"\") \\\n",
    "#   .load()\n",
    "\n",
    "# df_Fact_GA.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fact_GA]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f2ccfa3-864e-4f24-a90e-2360a4d53998",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dim_Sys_Users: VW_BI_CAT_SYS_USER\n",
    "\n",
    "df_vw_sys_user = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_BI_CAT_SYS_USER\").load()\n",
    "\n",
    "df_vw_sys_user.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.Dim_Sys_Users\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7d22290-4d9b-4e29-8dd6-b5c3b0b37ae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dim_Sys_Users_Chain: join view VW_SYS_USER_CHAIN_ACCESS_DASHBOARD, VW_BI_CAT_SYS_USER\n",
    "\n",
    "df_vw_sys_user_chain = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_SYS_USER_CHAIN_ACCESS_DASHBOARD\").load()\n",
    "\n",
    "df_vw_sys_user_chain.createOrReplaceTempView('SYSUSERS_CHAIN')\n",
    "\n",
    "df_vw_sys_user = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_BI_CAT_SYS_USER\").load()\n",
    "\n",
    "df_vw_sys_user.createOrReplaceTempView('SYSUSERS')\n",
    "\n",
    "df_sys_user_chain = spark.sql(\"\"\"\n",
    "SELECT C.user_id as sys_user, C.chain, U.email AS sys_user_email, C.country\n",
    "FROM SYSUSERS_CHAIN C \n",
    "INNER JOIN SYSUSERS U\n",
    "ON C.user_id = U.user_id\n",
    "\"\"\")\n",
    "\n",
    "#display(df_sys_urser_chain)\n",
    "\n",
    "df_sys_user_chain.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.Dim_Sys_Users_Chain\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccbf03fc-b13c-40c3-88ed-b0a769d405ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dim_Sys_Users_Member: join views VW_SYS_USER_MEMBER, VW_BI_CAT_SYS_USER, VW_CAT_MEMBER\n",
    "\n",
    "df_vw_sys_user_member = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_SYS_USER_MEMBER\").load()\n",
    "\n",
    "df_vw_sys_user_member.createOrReplaceTempView('SYSUSERS_MEMBER')\n",
    "\n",
    "df_vw_sys_user = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_BI_CAT_SYS_USER\").load()\n",
    "\n",
    "df_vw_sys_user.createOrReplaceTempView('SYSUSERS')\n",
    "\n",
    "df_vw_member = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_CAT_MEMBER\").load()\n",
    "\n",
    "df_vw_member.createOrReplaceTempView('MEMBERS')\n",
    "\n",
    "df_sys_user_member = spark.sql(\"\"\"\n",
    "SELECT M.sys_user, M.member, U.email AS sys_user_email, U.country_id\n",
    "FROM SYSUSERS_MEMBER M \n",
    "INNER JOIN SYSUSERS U\n",
    "ON M.sys_user = U.user_id\n",
    "UNION\n",
    "-- add users with role ADMIN (all CPGs)\n",
    "SELECT U.user_id AS sys_user, M.id AS member, U.email, M.country_id\n",
    "FROM SYSUSERS U\n",
    "CROSS JOIN MEMBERS M\n",
    "WHERE role IN ('ADMIN','GLOBAL_REPORT') and email like '%@%'\n",
    "UNION\n",
    "-- add users with role COUNTRY_ADMIN (all CPGs del mismo pais que el usuario)\n",
    "SELECT U.user_id AS sys_user, M.id AS member, U.email, U.country_id \n",
    "FROM SYSUSERS U\n",
    "INNER JOIN MEMBERS M ON U.country_id = M.country_id\n",
    "WHERE role IN ('COUNTRY_ADMIN','COUNTRY_MANAGER_ADMIN') and email like '%@%'\n",
    "\"\"\")\n",
    "\n",
    "#display(df_sys_urser_member)\n",
    "\n",
    "df_sys_user_member.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.Dim_Sys_Users_Member\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5335fc2-5985-4915-a641-f9ba500f7de6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dim_Sys_Users_ProductCategory: join views df_sys_user_member (previous dataframe), VW_CAT_BRAND, VW_CAT_PRODUCT\n",
    "\n",
    "df_sys_user_member.createOrReplaceTempView('USER_MEMBERS')\n",
    "\n",
    "df_dim_brand = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_CAT_BRAND\").load()\n",
    "\n",
    "df_dim_brand.createOrReplaceTempView('BRANDS')\n",
    "\n",
    "df_dim_product = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_CAT_PRODUCT\").load()\n",
    "\n",
    "df_dim_product.createOrReplaceTempView('PRODUCTS')\n",
    "\n",
    "df_sysuser_productcategory = spark.sql(\"\"\"\n",
    "SELECT DISTINCT UM.sys_user_email, UM.sys_user, UM.country_id, P.product_category_id\n",
    "FROM USER_MEMBERS UM\n",
    "INNER JOIN BRANDS B ON UM.member = B.member\n",
    "INNER JOIN PRODUCTS P ON B.id = P.brand_id\n",
    "\"\"\")\n",
    "\n",
    "#display(df_sysuser_productcategory)\n",
    "\n",
    "df_sysuser_productcategory.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_SysUser_ProductCategory]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "886a040c-bb07-4290-bc62-9a6cfea0de04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dim_ProductCategory: the data of this table is already in the product dimension, an independent table is created to solve the RLS problem in CPG\n",
    "\n",
    "df_product_category = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"query\",\"SELECT id, name FROM Staging.VW_BI_CAT_PRODUCT_CATEGORY\").load()\n",
    "\n",
    "df_product_category.createOrReplaceTempView('PRODUCT_CATEGORY')\n",
    "\n",
    "#display(df_product_category)\n",
    "\n",
    "df_product_category.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Product_Category]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "649f099c-3661-4b6b-a206-ba95c2da66cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stock Level\n",
    "\n",
    "#df_stock_level = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_STOCK_LEVEL\").load()\n",
    "\n",
    "#df_stock_level.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fact_Stock]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fa7d5d9-4f71-41ec-9e29-bd671423f7e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stock Level\n",
    "\n",
    "# This code will retry the transaction up to three times if a deadlock occurs, with a delay of 5 seconds between each attempt. If the transaction is successful, it will exit the loop. If the maximum number of retries is reached, it will raise the exception.\n",
    "\n",
    "max_retries = 3\n",
    "retry_delay = 5  # seconds\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        df_stock_level = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\", \"Staging.VW_STOCK_LEVEL\").load()\n",
    "\n",
    "        df_stock_level.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fact_Stock]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n",
    "        break  # Exit the loop if the transaction is successful\n",
    "    except Exception as e:\n",
    "        if \"deadlock\" in str(e):\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                raise\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "928aaece-7f33-4eac-a250-2bc64215fa1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dim_Cancellation_Reason: VW_CAT_ CANCELLATION_REASON\n",
    "\n",
    "df_cancellation_reason = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", \n",
    "conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_CAT_CANCELLATION_REASON\").load()\n",
    "\n",
    "#display(df_cancellation_reason)\n",
    "\n",
    "df_cancellation_reason.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Cancellation_Reason]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69a52766-8553-4155-b632-19c8450636b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dim_Member_Business: join views VW_Member_Chain and VW_Chain_Business\"\n",
    "\n",
    "df_member_chain = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_MEMBER_CHAIN_DASHBOARD\").load()\n",
    "\n",
    "df_member_chain.createOrReplaceTempView('MEMBER_CHAIN')\n",
    "\n",
    "#display(df_member_chain)\n",
    "\n",
    "df_chain_business = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_BI_CHAIN_BUSINESS_DASHBOARD\").load()\n",
    "\n",
    "df_chain_business.createOrReplaceTempView('CHAIN_BUSINESS')\n",
    "\n",
    "#display(df_chain_business)\n",
    "\n",
    "df_member_business = spark.sql(\"\"\"\n",
    "SELECT member, business_id\n",
    "FROM MEMBER_CHAIN MB\n",
    "INNER JOIN CHAIN_BUSINESS CB ON MB.chain = CB.chain_id\n",
    "GROUP BY member, business_id\n",
    "\"\"\")\n",
    "\n",
    "#display(df_member_business)\n",
    "\n",
    "df_member_business.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Dim_Member_Business]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "655ee755-d4e2-4480-a471-fd802704b8c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fast_order_tracking, Fast_order_tracking_found_line, Fast_order_tracking_not_found_line\n",
    "\n",
    "df_fast_order_tracking_found_line = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_FAST_ORDER_TRACKING_FOUND_LINE\").load()\n",
    "\n",
    "df_fast_order_tracking_found_line.createOrReplaceTempView('FAST_ORDER_FOUND_LINE')\n",
    "\n",
    "df_Fast_Order_Tracking = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_FAST_ORDER_TRACKING\").load()\n",
    "\n",
    "df_Fast_Order_Tracking.createOrReplaceTempView('FAST_ORDER_TRACKING')\n",
    "\n",
    "df_Fact_Order_Line = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"companyDummy.Fact_Order_Line\").load()\n",
    "\n",
    "df_Fact_Order_Line.createOrReplaceTempView('FACT_ORDER_LINE')\n",
    "\n",
    "df_Fact_Order = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"companyDummy.Fact_Order\").load()\n",
    "\n",
    "df_Fact_Order.createOrReplaceTempView('FACT_ORDER')\n",
    "\n",
    "\n",
    "### Fast_Order_Tracking_Found_line\n",
    "\n",
    "df_view_found_line = spark.sql(\"\"\"\n",
    "SELECT fa.*, product_purchase\n",
    "from FAST_ORDER_FOUND_LINE fa\n",
    "inner join \n",
    "\t(\n",
    "\tSELECT fa.productId, fa.fastOrderTrackingId,\n",
    "\t\t ROW_NUMBER() OVER (PARTITION BY fa.productId, fa.fastOrderTrackingId ORDER BY fa.fastOrderTrackingId,fa.productId) AS row_num,\n",
    "\t\t CASE WHEN lo.product_id is null THEN 'NOT PURCHASE' ELSE 'PURCHASE' END as product_purchase\n",
    "\tFROM FAST_ORDER_FOUND_LINE fa\n",
    "\tINNER JOIN FAST_ORDER_TRACKING ft\n",
    "\t\tON fa.fastOrderTrackingId = ft.id\n",
    "\tLEFT JOIN FACT_ORDER_LINE lo\n",
    "\t\tON  ft.orderId = lo.order\n",
    "\t\tAND lo.product_id = fa.productId\n",
    "\t\tAND lo.product_flag IN ('Normal Product', 'Promo Product')\n",
    "\t\tAND lo.valid = 1\n",
    "\t) a\n",
    "    on fa.fastOrderTrackingId = a.fastOrderTrackingId\n",
    "    and fa.productId = a.productId\n",
    "\t  and row_num = 1\n",
    "\"\"\")\n",
    "\n",
    "df_view_found_line.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fast_Order_Tracking_Found_line]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n",
    "\n",
    "\n",
    "### Fast_order_tracking\n",
    "\n",
    "df_view_fast_order = spark.sql(\"\"\"\n",
    "SELECT ft.*,\n",
    "    CASE WHEN  ft.orderId is null THEN 'NO PURCHASE'\n",
    "        ELSE 'PURCHASE' END as RecommendationFunnel1,\n",
    "    CASE WHEN MORE_ALGOLIA is null then NULL\n",
    "         WHEN MORE_ALGOLIA = 0 AND MORE_ORDERS = 0 THEN 'PERFECT_MATCH'\n",
    "         WHEN MORE_ALGOLIA = 0 AND MORE_ORDERS > 0 THEN 'ADD'\n",
    "         WHEN MORE_ORDERS = 0 AND MORE_ALGOLIA > 0 THEN 'DROP'\n",
    "    ELSE 'PARTIAL_MATCH' END as RecommendationFunnel2,\n",
    "fo.created_at AS order_created_at,\n",
    "fo.valid AS order_valid\n",
    "FROM FAST_ORDER_TRACKING ft\n",
    "LEFT JOIN FACT_ORDER fo ON ft.orderId = fo.id\n",
    "LEFT JOIN \n",
    "\t(\n",
    "    SELECT orderId, COUNT(orderId) AS ORDERS,\n",
    "        SUM(CASE WHEN (productId = product_id)  AND ( product_id is not null) THEN 1 ELSE 0 END) as MATCH,\n",
    "        SUM(CASE WHEN (product_id is null)  AND ( productId is not null) THEN 1 ELSE 0 END) as MORE_ALGOLIA,\n",
    "        SUM(CASE WHEN (productId is null)  AND ( product_id is not null) THEN 1 ELSE 0 END) as MORE_ORDERS\n",
    "    FROM \n",
    "\t(\n",
    "\t\tSELECT orderId,  product_id, productId\n",
    "\t\tFROM \n",
    "\t\t(\n",
    "\t\t\tSELECT ft.orderId,  lo.product_id, fa.productId\n",
    "\t\t\tFROM FAST_ORDER_TRACKING ft\n",
    "\t\t\tINNER JOIN FAST_ORDER_FOUND_LINE fa\n",
    "\t\t\t\tON fa.fastOrderTrackingId = ft.id\n",
    "\t\t\tLEFT JOIN FACT_ORDER_LINE lo\n",
    "\t\t\t\tON  ft.orderId = lo.order\n",
    "\t\t\t\tAND lo.product_id = fa.productId\n",
    "\t\t\t\tAND lo.product_flag IN ('Normal Product', 'Promo Product')\n",
    "\t\t\t\tAND lo.valid = 1\n",
    "\t\t) more_orders_explode\n",
    "\t\tUNION ALL\n",
    "\t\tSELECT orderId,  product_id, productId\n",
    "\t\tFROM \n",
    "\t\t(\n",
    "\t\t\tSELECT ft.orderId,  lo.product_id, fa.productId\n",
    "\t\t\tFROM FAST_ORDER_TRACKING ft\n",
    "\t\t\tINNER JOIN FACT_ORDER_LINE lo\n",
    "\t\t\t\tON  ft.orderId = lo.order\n",
    "\t\t\tLEFT JOIN FAST_ORDER_FOUND_LINE fa\n",
    "\t\t\t\tON fa.fastOrderTrackingId = ft.id\n",
    "\t\t\t\tAND lo.product_id = fa.productId \n",
    "\t\t\t\tAND lo.product_flag IN ('Normal Product', 'Promo Product')\n",
    "\t\t\t\tAND lo.valid = 1\n",
    "\t\t\tWHERE fa.productId  is NULL \n",
    "\t\t) more_algolia_explode\n",
    "\t) Union_cases\n",
    "    GROUP BY orderId\n",
    "\t) l\n",
    "    ON l.orderId = ft.orderId\n",
    "\"\"\")\n",
    "\n",
    "#display(df_view_fast_order)\n",
    "\n",
    "df_view_fast_order.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fast_Order_Tracking]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n",
    "\n",
    "\n",
    "### Fast_order_tracking_not_found_line\n",
    "\n",
    "df_fast_order_tracking_not_found_line = spark.read.format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).option(\"dbtable\",\"Staging.VW_FAST_ORDER_TRACKING_NOT_FOUND_LINE\").load()\n",
    "\n",
    "df_fast_order_tracking_not_found_line.write.mode(\"overwrite\").format(\"jdbc\").option(\"url\", conf['jdbcUrl_destination']).option(\"driver\", conf['jdbcDriver_destination']).option(\"dbtable\", \"companyDummy.[Fast_Order_Tracking_Not_Found_line]\").option(\"user\", conf['jdbcUsername_destination']).option(\"password\", conf['jdbcPassword_destination']).save()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Easy24_data_ingest_v2_test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
